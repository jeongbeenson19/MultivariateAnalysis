{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "오즈 비(Odds ratio)는 통계학에서 사용되는 개념으로, 두 사건 간의 상대적인 발생 확률을 나타냅니다. 주로 이항 분포나 로지스틱 회귀 모델 등에서 사용되며, 두 가지 카테고리로 나뉜 사건의 발생 확률을 비교하는 데 사용됩니다.\n",
        "\n",
        "오즈 비는 다음과 같이 정의됩니다:\n",
        "\n",
        "$$\n",
        "\\text{Odds Ratio} = \\frac{{\\text{Odds of event 1}}}{{\\text{Odds of event 2}}}\n",
        "$$\n",
        "\n",
        "여기서, \"Odds of event 1\"은 이벤트 1이 발생할 확률과 발생하지 않을 확률의 비율을 의미하며, \"Odds of event 2\"는 이벤트 2가 발생할 확률과 발생하지 않을 확률의 비율을 의미합니다.\n",
        "\n",
        "오즈 비가 1보다 크면 이벤트 1의 발생이 이벤트 2의 발생보다 더 높은 확률을 의미합니다. 오즈 비가 1보다 작으면 이벤트 2의 발생이 이벤트 1의 발생보다 더 높은 확률을 의미합니다. 오즈 비가 1이면 두 사건의 발생 확률이 서로 동일합니다.\n",
        "\n",
        "오즈 비는 주로 효과 크기나 관련성을 비교하는 데 사용됩니다. 예를 들어, 치료 그룹과 대조 그룹 간의 치료 효과를 비교하거나, 두 가지 변수 간의 관련성을 파악하는 데에 활용될 수 있습니다."
      ],
      "metadata": {
        "id": "3V54iC1CryR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "로지스틱 회귀(Logistic Regression)는 분류 문제를 다루는 데에 사용되는 통계적인 기법 중 하나입니다. 이름은 회귀(regression)가 들어가지만, 실제로는 분류(classification) 알고리즘으로 사용됩니다. 이 알고리즘은 입력 특성(feature)을 사용하여 이진 분류(binary classification)를 수행합니다. 이진 분류는 두 개의 클래스 중 하나를 선택하는 문제를 의미합니다.\n",
        "\n",
        "로지스틱 회귀의 기본 아이디어는 입력 특성과 각 클래스 사이의 선형 관계를 모델링하는 것입니다. 로지스틱 회귀는 선형 회귀와 유사하게 입력 특성에 대한 가중치(weight)와 편향(bias)을 학습합니다. 그러나 로지스틱 회귀의 출력은 로지스틱 함수 또는 시그모이드 함수(sigmoid function)를 통과합니다. 시그모이드 함수는 0과 1 사이의 값을 출력하며, 이를 클래스의 확률로 해석할 수 있습니다.\n",
        "\n",
        "로지스틱 회귀는 주로 이진 분류 문제를 다루지만, 여러 개의 클래스를 분류하는 다중 클래스 분류(multiclass classification) 문제에도 확장될 수 있습니다. 다중 클래스 분류에서는 일대다(one-vs-rest) 또는 일대일(one-vs-one) 전략을 사용하여 각 클래스를 다른 클래스와 구별하도록 모델을 학습합니다.\n",
        "\n",
        "로지스틱 회귀는 간단하고 해석하기 쉬우며, 데이터가 선형적으로 구분될 때 잘 작동합니다. 또한, 로지스틱 회귀는 기본적인 분류 문제를 다루는 데에 많이 사용되며, 이를 기반으로 다양한 확장된 모델들이 개발되었습니다."
      ],
      "metadata": {
        "id": "O6s2RxhGtGWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "로지스틱 회귀의 함수식은 다음과 같습니다. 이는 로지스틱 함수 또는 시그모이드 함수(sigmoid function)로 표현됩니다.\n",
        "\n",
        "로지스틱 함수는 입력값의 범위를 0과 1 사이로 압축하는 비선형 함수로, 이진 분류에서 각 클래스의 확률을 추정하는 데에 사용됩니다.\n",
        "\n",
        "로지스틱 함수의 수식은 다음과 같습니다:\n",
        "\n",
        "$$\n",
        "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
        "$$\n",
        "\n",
        "여기서 \\(x\\)는 입력값이며, $\\sigma(x)$는 해당 입력값에 대한 로지스틱 함수의 출력값입니다. \\(e\\)는 자연상수(euler's number)로 약 2.718의 값을 갖습니다.\n",
        "\n",
        "로지스틱 함수의 특징은 다음과 같습니다:\n",
        "- 입력값이 음의 무한대에 가까워지면 출력값은 0에 가까워집니다.\n",
        "- 입력값이 양의 무한대에 가까워지면 출력값은 1에 가깝습니다.\n",
        "- 입력값이 0일 때, 출력값은 0.5가 됩니다.\n",
        "\n",
        "로지스틱 함수는 선형 회귀의 결과를 0과 1 사이의 값으로 변환하여 확률값으로 해석할 수 있게 합니다. 따라서 로지스틱 회귀는 이진 분류에서 각 클래스의 확률을 추정하는 데에 사용됩니다."
      ],
      "metadata": {
        "id": "3Qkm2YsYtlt5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vf2jf6rVl0Jj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "x_data = np.array([[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]])\n",
        "y_data = np.array([0, 0, 0, 1, 1, 1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression().fit(x_data, y_data)\n",
        "print(clf.coef_)\n",
        "print(clf.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8RVz2zLvxPI",
        "outputId": "0d1c37a5-1904-4361-c761-2eaf3452bf17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.08671177 0.45797507]]\n",
            "[-4.87989555]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "x_data_1 = sm.add_constant(x_data)\n",
        "log_reg = sm.Logit(y_data, x_data_1).fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUKwZGQ2xlgB",
        "outputId": "9e9a823c-51b8-4150-c4e9-3f9effc1e0dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Maximum number of iterations has been exceeded.\n",
            "         Current function value: 0.000000\n",
            "         Iterations: 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "oJQYA77qyLxB",
        "outputId": "3d6079d6-51b4-426c-e17b-2e3a78422819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                           Logit Regression Results                           \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   No. Observations:                    6\n",
              "Model:                          Logit   Df Residuals:                        3\n",
              "Method:                           MLE   Df Model:                            2\n",
              "Date:                Thu, 11 Apr 2024   Pseudo R-squ.:                   1.000\n",
              "Time:                        02:15:00   Log-Likelihood:            -1.0370e-08\n",
              "converged:                      False   LL-Null:                       -4.1589\n",
              "Covariance Type:            nonrobust   LLR p-value:                   0.01563\n",
              "==============================================================================\n",
              "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const        -87.7065   4.49e+04     -0.002      0.998   -8.82e+04     8.8e+04\n",
              "x1            19.6419   1.33e+04      0.001      0.999   -2.61e+04    2.61e+04\n",
              "x2             9.4922   1.02e+04      0.001      0.999      -2e+04       2e+04\n",
              "==============================================================================\n",
              "\n",
              "Complete Separation: The results show that there iscomplete separation or perfect prediction.\n",
              "In this case the Maximum Likelihood Estimator does not exist and the parameters\n",
              "are not identified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Logit Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>   <td>     6</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>     3</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Thu, 11 Apr 2024</td> <th>  Pseudo R-squ.:     </th>   <td> 1.000</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>02:15:00</td>     <th>  Log-Likelihood:    </th> <td>-1.0370e-08</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>converged:</th>             <td>False</td>      <th>  LL-Null:           </th>  <td> -4.1589</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.01563</td>  \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>  -87.7065</td> <td> 4.49e+04</td> <td>   -0.002</td> <td> 0.998</td> <td>-8.82e+04</td> <td>  8.8e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>   19.6419</td> <td> 1.33e+04</td> <td>    0.001</td> <td> 0.999</td> <td>-2.61e+04</td> <td> 2.61e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>    9.4922</td> <td> 1.02e+04</td> <td>    0.001</td> <td> 0.999</td> <td>   -2e+04</td> <td>    2e+04</td>\n",
              "</tr>\n",
              "</table><br/><br/>Complete Separation: The results show that there iscomplete separation or perfect prediction.<br/>In this case the Maximum Likelihood Estimator does not exist and the parameters<br/>are not identified."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}   &        y         & \\textbf{  No. Observations:  } &         6    \\\\\n\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &         3    \\\\\n\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &         2    \\\\\n\\textbf{Date:}            & Thu, 11 Apr 2024 & \\textbf{  Pseudo R-squ.:     } &     1.000    \\\\\n\\textbf{Time:}            &     02:15:00     & \\textbf{  Log-Likelihood:    } & -1.0370e-08  \\\\\n\\textbf{converged:}       &      False       & \\textbf{  LL-Null:           } &    -4.1589   \\\\\n\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } &   0.01563    \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const} &     -87.7065  &     4.49e+04     &    -0.002  &         0.998        &    -8.82e+04    &      8.8e+04     \\\\\n\\textbf{x1}    &      19.6419  &     1.33e+04     &     0.001  &         0.999        &    -2.61e+04    &     2.61e+04     \\\\\n\\textbf{x2}    &       9.4922  &     1.02e+04     &     0.001  &         0.999        &       -2e+04    &        2e+04     \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{Logit Regression Results}\n\\end{center}\n\nComplete Separation: The results show that there iscomplete separation or perfect prediction. \\newline\n In this case the Maximum Likelihood Estimator does not exist and the parameters \\newline\n are not identified."
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "Lvw5PqVJ1iJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "로지스틱 회귀에서 교차 엔트로피 손실 함수는 모델의 예측과 실제 클래스 간의 차이를 측정하여 모델을 학습하는 데에 사용됩니다. 이를 통해 모델이 이진 분류(binary classification) 문제에서 클래스를 올바르게 분류하도록 학습됩니다.\n",
        "\n",
        "로지스틱 회귀에서는 입력 변수의 선형 조합을 로지스틱 함수(시그모이드 함수)에 적용하여 확률을 출력하고, 이 확률을 기반으로 클래스를 예측합니다. 그리고 예측된 확률과 실제 클래스 간의 차이를 최소화하기 위해 교차 엔트로피 손실 함수를 최소화하는 방향으로 모델의 가중치(weight)와 편향(bias)을 조정합니다.\n",
        "\n",
        "로지스틱 회귀에서 이진 교차 엔트로피(binary cross-entropy) 손실 함수는 다음과 같이 정의됩니다:\n",
        "\n",
        "$$\n",
        "\\text{Binary Cross-Entropy Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} [y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i)]\n",
        "$$\n",
        "\n",
        "여기서 \\(y_i\\)는 실제 클래스, \\(p_i\\)는 모델이 예측한 클래스의 확률을 나타냅니다.\n",
        "\n",
        "로지스틱 회귀 모델을 학습할 때는 이 손실 함수를 최소화하는 방향으로 모델의 파라미터를 업데이트합니다. 이를 위해 일반적으로 경사 하강법(gradient descent)이 사용됩니다. 경사 하강법을 통해 손실 함수의 기울기를 계산하고, 기울기의 반대 방향으로 파라미터를 조정하여 손실을 최소화합니다.\n",
        "\n",
        "따라서 로지스틱 회귀 모델은 교차 엔트로피 손실 함수를 통해 학습되며, 이를 통해 이진 분류 문제에서 클래스를 예측하고 분류합니다."
      ],
      "metadata": {
        "id": "WWvH2J3H4eZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VBDWMU673jR",
        "outputId": "708819df-a0b1-4173-c4a6-7cfb82cf9b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7940e859d9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.LongTensor(y_data)"
      ],
      "metadata": {
        "id": "mdK097Sw4ZTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NetModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(2, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ],
      "metadata": {
        "id": "G3LRTaqv4y2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NetModel()\n",
        "criterian = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)"
      ],
      "metadata": {
        "id": "VZYAyAIj6I_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIfz7dcF6ndy",
        "outputId": "c23a1ae1-3ad9-45a0-c719-d79fec109863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8440,  0.7005],\n",
              "        [-1.1089,  0.6159],\n",
              "        [-1.4441, -0.2686],\n",
              "        [-1.6856, -0.0864],\n",
              "        [-1.9739, -0.4376],\n",
              "        [-2.2857, -1.0555]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 20\n",
        "for epoch in range(1, n_epoch+1):\n",
        "  hypothesis = model(x_train)\n",
        "\n",
        "  loss = criterian(hypothesis, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print(f\"{epoch}번째 loss 출력: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xHjUmFL6r6h",
        "outputId": "40e18ea3-bd56-4533-f051-9b1055c9a176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1번째 loss 출력: 0.7912620902061462\n",
            "2번째 loss 출력: 0.7890289425849915\n",
            "3번째 loss 출력: 0.7868162989616394\n",
            "4번째 loss 출력: 0.7846238017082214\n",
            "5번째 loss 출력: 0.7824512124061584\n",
            "6번째 loss 출력: 0.7802982330322266\n",
            "7번째 loss 출력: 0.7781646847724915\n",
            "8번째 loss 출력: 0.7760502696037292\n",
            "9번째 loss 출력: 0.7739548087120056\n",
            "10번째 loss 출력: 0.7718780636787415\n",
            "11번째 loss 출력: 0.769819974899292\n",
            "12번째 loss 출력: 0.7677801251411438\n",
            "13번째 loss 출력: 0.7657585144042969\n",
            "14번째 loss 출력: 0.7637550234794617\n",
            "15번째 loss 출력: 0.7617692351341248\n",
            "16번째 loss 출력: 0.7598010897636414\n",
            "17번째 loss 출력: 0.7578504681587219\n",
            "18번째 loss 출력: 0.7559171319007874\n",
            "19번째 loss 출력: 0.7540009617805481\n",
            "20번째 loss 출력: 0.7521018385887146\n"
          ]
        }
      ]
    }
  ]
}